{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 230\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# use the same criteria from the porject results\u001b[39;00m\n\u001b[1;32m    228\u001b[0m codes \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39mquantity \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m20\u001b[39m]\u001b[38;5;241m.\u001b[39mcode\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m--> 230\u001b[0m ints_and_data \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc_date\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpcs_m\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mmerge(\u001b[43mi_x\u001b[49m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    232\u001b[0m locations \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mlocation\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m    234\u001b[0m data \u001b[38;5;241m=\u001b[39m ints_and_data[(ints_and_data\u001b[38;5;241m.\u001b[39mcode\u001b[38;5;241m.\u001b[39misin(codes)) \u001b[38;5;241m&\u001b[39m (ints_and_data\u001b[38;5;241m.\u001b[39mlocation\u001b[38;5;241m.\u001b[39misin(locations))]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i_x' is not defined"
     ]
    }
   ],
   "source": [
    "# sys, file and nav packages:\n",
    "import datetime as dt\n",
    "import json\n",
    "import functools\n",
    "import time\n",
    "\n",
    "# math packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "# charting:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import IPython\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display\n",
    "from myst_nb import glue\n",
    "\n",
    "import time\n",
    "\n",
    "start_date = '2020-03-01'\n",
    "end_date ='2021-05-31'\n",
    "\n",
    "a_qty = 20\n",
    "\n",
    "a_fail_rate = .5\n",
    "\n",
    "use_fail = False\n",
    "\n",
    "unit_label = 'p/100m'\n",
    "\n",
    "# survey data:\n",
    "dfx= pd.read_csv('resources/checked_sdata_eos_2020_21.csv')\n",
    "\n",
    "dfBeaches = pd.read_csv(\"resources/beaches_with_land_use_rates.csv\")\n",
    "dfCodes = pd.read_csv(\"resources/codes_with_group_names_2015.csv\")\n",
    "\n",
    "# set the index of the beach data to location slug\n",
    "dfBeaches.set_index('slug', inplace=True)\n",
    "\n",
    "# set the index of to codes\n",
    "dfCodes.set_index(\"code\", inplace=True)\n",
    "\n",
    "# code description map\n",
    "code_d_map = dfCodes.description\n",
    "\n",
    "# code material map\n",
    "code_m_map = dfCodes.material\n",
    "\n",
    "pdtype = pd.core.frame.DataFrame\n",
    "pstype = pd.core.series.Series\n",
    "\n",
    "def scaleTheColumn(x):\n",
    "    \n",
    "    xmin = x.min()\n",
    "    xmax = x.max()\n",
    "    xscaled = (x-xmin)/(xmax-xmin)\n",
    "    \n",
    "    return xscaled\n",
    "\n",
    "def cleanSurveyResults(data):\n",
    "    # performs data cleaning operations on the\n",
    "    # default data\n",
    "    \n",
    "    data['loc_date'] = list(zip(data.location, data[\"date\"]))\n",
    "    data['date'] = pd.to_datetime(data[\"date\"])\n",
    "    \n",
    "    # get rid of microplastics\n",
    "    mcr = data[data.groupname == \"micro plastics (< 5mm)\"].code.unique()\n",
    "    \n",
    "    # replace the bad code\n",
    "    data.code = data.code.replace('G207', 'G208')\n",
    "    data = data[~data.code.isin(mcr)]\n",
    "    \n",
    "    # walensee has no landuse values\n",
    "    data = data[data.water_name_slug != 'walensee']   \n",
    "    \n",
    "    return data\n",
    "\n",
    "class SurveyResults:\n",
    "    \"\"\"Creates a dataframe from a valid filename. Assigns the column names and defines a list of\n",
    "    codes and locations that can be used in the CodeData class.\n",
    "    \"\"\"\n",
    "    \n",
    "    file_name = 'resources/checked_sdata_eos_2020_21.csv'\n",
    "    columns_to_keep=[\n",
    "        'loc_date',\n",
    "        'location', \n",
    "        'river_bassin',\n",
    "        'water_name_slug',\n",
    "        'city',\n",
    "        'w_t', \n",
    "        'intersects', \n",
    "        'code', \n",
    "        'pcs_m',\n",
    "        'quantity'\n",
    "    ]\n",
    "        \n",
    "    def __init__(self, data: str = file_name, clean_data: bool = True, columns: list = columns_to_keep, w_t: str = None):\n",
    "        self.dfx = pd.read_csv(data)\n",
    "        self.df_results = None\n",
    "        self.locations = None\n",
    "        self.valid_codes = None\n",
    "        self.clean_data = clean_data\n",
    "        self.columns = columns\n",
    "        self.w_t = w_t\n",
    "        \n",
    "    def validCodes(self):\n",
    "        # creates a list of unique code values for the data set    \n",
    "        conditions = [\n",
    "            isinstance(self.df_results, pdtype),\n",
    "            \"code\" in self.df_results.columns\n",
    "        ]\n",
    "\n",
    "        if all(conditions):\n",
    "\n",
    "            try:\n",
    "                valid_codes = self.df_results.code.unique()\n",
    "            except ValueError:\n",
    "                print(\"There was an error retrieving the unique code names, self.df.code.unique() failed.\")\n",
    "                raise\n",
    "            else:\n",
    "                self.valid_codes = valid_codes\n",
    "                \n",
    "        \n",
    "    def surveyResults(self):\n",
    "        \n",
    "        # if this method has been called already\n",
    "        # return the result\n",
    "        if self.df_results is not None:\n",
    "            return self.df_results\n",
    "        \n",
    "        # for the default data self.clean data must be called        \n",
    "        if self.clean_data is True:\n",
    "            fd = cleanSurveyResults(self.dfx)\n",
    "            \n",
    "        # if the data is clean then if can be used directly\n",
    "        else:\n",
    "            fd = self.dfx\n",
    "        \n",
    "        # filter the data by the variable w_t\n",
    "        if self.w_t is not None:\n",
    "            fd = fd[fd.w_t == self.w_t]            \n",
    "         \n",
    "        # keep only the required columns\n",
    "        if self.columns:\n",
    "            fd = fd[self.columns]\n",
    "        \n",
    "        # assign the survey results to the class attribute\n",
    "        self.df_results = fd\n",
    "        \n",
    "        # define the list of codes in this df\n",
    "        self.validCodes()\n",
    "        \n",
    "        return self.df_results\n",
    "    \n",
    "    def surveyLocations(self):\n",
    "        if self.locations is not None:\n",
    "            return self.locations\n",
    "        if self.df_results is not None:\n",
    "            self.locations = self.dfResults.location.unique()\n",
    "            return self.locations\n",
    "        else:\n",
    "            print(\"There is no survey data loaded\")\n",
    "            return None    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this defines the css rules for the note-book table displays\n",
    "header_row = {'selector': 'th:nth-child(1)', 'props': f'background-color: #FFF;'}\n",
    "even_rows = {\"selector\": 'tr:nth-child(even)', 'props': f'background-color: rgba(139, 69, 19, 0.08);'}\n",
    "odd_rows = {'selector': 'tr:nth-child(odd)', 'props': 'background: #FFF;'}\n",
    "table_font = {'selector': 'tr', 'props': 'font-size: 12px;'}\n",
    "table_css_styles = [even_rows, odd_rows, table_font, header_row]\n",
    "\n",
    "# the intersect data\n",
    "dtoi_o = pd.read_csv(\"resources/buffer_output/distance_to_intersection.csv\")\n",
    "\n",
    "columns = [ \"river_bass\", \"feature\", \"city\", \"location\", \"NAMN_2\", \"BREITE\", \"KLASSE_2\", \"HOC\", \"feature\", \"distance\", \"OBJVAL\"]\n",
    "dtoi = dtoi_o[columns].copy()\n",
    "rename = {\"NAMN_2\":\"name\", \"BREITE\":\"size\", \"KLASSE_2\":\"class\", \"HOC\":\"hoc\", \"NAMN\":\"name\",\"KLASSE\":\"class\"}\n",
    "dtoi.rename(columns=rename, inplace=True)\n",
    "\n",
    "# designate a column to merge on\n",
    "dtoi[\"merge_col\"] = list(zip(dtoi.location, dtoi[\"name\"], dtoi[\"size\"], dtoi[\"class\"]))\n",
    "dtoi.drop_duplicates(\"merge_col\", inplace=True)\n",
    "\n",
    "# the length data\n",
    "dtoi_l = pd.read_csv(\"resources/buffer_output/intersection_length.csv\")\n",
    "columns = [\"river_bass\", \"feature\", \"city\", \"location\", \"NAMN\", \"BREITE\", \"KLASSE\", \"HOC\", \"feature\", \"length\", \"OBJVAL\"]\n",
    "dtol = dtoi_l[columns].copy()\n",
    "dtol.rename(columns=rename, inplace=True)\n",
    "\n",
    "# designate a column to merge on\n",
    "dtol[\"merge_col\"] = list(zip(dtol.location, dtol[\"name\"], dtol[\"size\"], dtol[\"class\"]))\n",
    "\n",
    "# merge the lenght and intersection data\n",
    "these_merge_cols = [\"length\",\"name\",\"merge_col\"]\n",
    "ind = dtoi.merge(dtol[these_merge_cols], on=\"merge_col\")\n",
    "ind = ind[[\"location\", \"name_x\",\"distance\", \"length\", \"size\", \"class\"]].copy()\n",
    "\n",
    "# collecting survey data\n",
    "fdx = SurveyResults()\n",
    "df = fdx.surveyResults()\n",
    "df = df[df.location.isin(ind.location.unique())].copy()\n",
    "df = df[df.w_t != \"r\"]\n",
    "\n",
    "no_luse_data = [\"linth_route9brucke\",\n",
    "                \"seez_spennwiesenbrucke\",\n",
    "                'limmat_dietikon_keiserp',\n",
    "                \"seez\"]\n",
    "\n",
    "# use the same criteria from the porject results\n",
    "codes = df[df.quantity > 20].code.unique()\n",
    "\n",
    "ints_and_data = df[[\"loc_date\",\"location\", \"city\", \"code\", \"pcs_m\"]].merge(i_x, on=\"location\")\n",
    "\n",
    "locations = df.location.unique()\n",
    "\n",
    "data = ints_and_data[(ints_and_data.code.isin(codes)) & (ints_and_data.location.isin(locations))].copy()\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "columns = [\"distance\", \"length\", \"size\", \"class\"]\n",
    "\n",
    "def collectCorrelation(data, codes, columns):\n",
    "    results = []\n",
    "    for code in codes:\n",
    "        d = data[data.code == code]\n",
    "        dx = d.pcs_m.values\n",
    "        for name in columns:\n",
    "            dy = d[name].values\n",
    "            c, p = stats.spearmanr(dx, dy)\n",
    "            \n",
    "            results.append({\"code\":code, \"variable\":name, \"rho\":c, \"p\":p})\n",
    "    return results\n",
    "\n",
    "def resultsDf(rhovals: pdtype = None, pvals: pdtype = None)-> pdtype:\n",
    "    results_df = []\n",
    "    for i, n in enumerate(pvals.index):\n",
    "        arow_of_ps = pvals.iloc[i]\n",
    "        p_fail = arow_of_ps[ arow_of_ps > 0.05]\n",
    "        arow_of_rhos = rhovals.iloc[i]\n",
    "        \n",
    "        for label in p_fail.index:\n",
    "            arow_of_rhos[label] = 0\n",
    "        results_df.append(arow_of_rhos)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def styleBufferResults(buffer_results):\n",
    "    buffer_results.columns.name = None\n",
    "    bfr = buffer_results.style.format(precision=2).set_table_styles(table_css_styles)\n",
    "    bfr = bfr.background_gradient(axis=None, vmin=buffer_results.min().min(), vmax=buffer_results.max().max(), cmap=\"coolwarm\")\n",
    "    bfr = bfr.applymap_index(rotateText, axis=1)\n",
    "    \n",
    "    return bfr           \n",
    "            \n",
    "\n",
    "\n",
    "corellation_results = collectCorrelation(data, codes, columns)\n",
    "crp = pd.DataFrame(corellation_results)\n",
    "pvals = crp.pivot(index=\"code\", columns=\"variable\", values=\"p\")\n",
    "rhovals = crp.pivot(index=\"code\", columns=\"variable\", values=\"rho\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# River discharge and lake intersections\n",
    "\n",
    "In the intitial report and in the project-results sample the influence of river inputs was quantitied by the number of river intersects within 1500 m of a survey location. With this method 13 possible correlations were identified, 11 positive and two negative. This method does not take into account the distance to the intersection, the lenght of the river section withing the 1500 m buffer nor does it consider the size of the inputs.\n",
    "\n",
    "Here we consider the distance, the length, the size and the class of each river within 2 km of the survey location. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} resources/images/stream_length_buffer_land_use.jpeg\n",
    "---\n",
    "name: dist_to_int\n",
    "---\n",
    "` `\n",
    "```\n",
    "{numref}`figure %s: <dist_to_int>` Measuring the distance to the intersection and length of the intersection in the 2 k buffer. Location: grand-clos, St. Gingolph - Lac Léman."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the values from the map layer\n",
    "\n",
    "The map layers that are publicly available have changed since the land-use attributes were originally considered for the project. At that time we did not consider the length or distance. The size and the class of each river was not indicated on the previous map layers either. All that has changed:\n",
    "\n",
    "1. There are fewer rivers and streams in the new map layers\n",
    "2. Each river (section) is labled with the size, class, name and designated as man-made or natural.\n",
    "\n",
    "To extract the required data for the analysis for each location and river the following steps were followed:\n",
    "\n",
    "1. Identify locations of interest\n",
    "2. Construct a buffer around each point\n",
    "3. Mark the intersection of the river with the buffer and the lake\n",
    "4. Calculate the length of that section\n",
    "5. Calculate the straight line distance from the survey location to the point where the river leaves the buffer and enters the lake\n",
    "\n",
    "Most locations have more than one intersection. Which means that the survey result for a code is considered under all the possible conditions for each location. The results from St. Gingolph illustrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data[(data.location == 'grand-clos') & (data.code == \"Gfrags\")&(data.loc_date == (\"grand-clos\", \"2020-05-07\"))].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "Only surveys from lakes are considered. While it is possible to do the same analysis on river locations, the results would not be comparable. Lakes are zones of low flow in a river bassin. When products/objects enter the lake from a river, they go from a zone of high flow to low flow. Objects of different densities may travel different distances once they hit the lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "## The survey results\n",
    "locations = df.location.unique()\n",
    "samples = df.loc_date.unique()\n",
    "lakes = df[df.w_t == \"l\"].drop_duplicates(\"loc_date\").w_t.value_counts().values[0]\n",
    "\n",
    "codes_identified = df[df.quantity > 0].code.unique()\n",
    "codes_possible = df.code.unique()\n",
    "total_id = df.quantity.sum()\n",
    "\n",
    "data_summary = {\n",
    "    \"n locations\": len(locations),\n",
    "    \"n samples\": len(samples),\n",
    "    \"n lake samples\": lakes,\n",
    "    \"n identified object types\": len(codes_identified),\n",
    "    \"n possible object types\": len(codes_possible),\n",
    "    \"total number of objects\": total_id\n",
    "}\n",
    "\n",
    "pd.DataFrame(index = data_summary.keys(), data=data_summary.values(), columns=[\"total\"]).style.set_table_styles(table_css_styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "styleBufferResults(pd.DataFrame(resultsDf(rhovals, pvals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "\n",
    "__negative correlations__ the size and class are in the inverse of the distance and lenght paramenters. That is that rivers with a large size paramater are smaller than those with a small size parameter. The class parameter is the stream classification in relation to the ocean. Therefore, objects that are positively correlated with size and class were found more often at the intersects of smaller and less important rivers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total correlations, total positive correlations, total negative corrrelations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def countTheNumberOfCorrelationsPerBuffer(pvals: pdtype = None, rhovals: pdtype = None) -> (pdtype, pstype):\n",
    "    \n",
    "    # the number of times p <= 0.05\n",
    "    number_p_less_than = (pvals <= 0.05).sum()\n",
    "    number_p_less_than.name = \"correlated\"\n",
    "    \n",
    "    # the number of postive correlations\n",
    "    number_pos = (rhovals > 0).sum()\n",
    "    number_pos.name = \"positive\"\n",
    "    \n",
    "    # the number of negative correlations\n",
    "    number_neg = (rhovals < 0).sum()\n",
    "    number_neg.name = \"negative\"\n",
    "\n",
    "    ncorrelated = pd.DataFrame([number_p_less_than, number_pos, number_neg])\n",
    "    ncorrelated[\"total\"] = ncorrelated.sum(axis=1)\n",
    "    totals = ncorrelated.total\n",
    "    \n",
    "    \n",
    "    return ncorrelated, totals\n",
    "\n",
    "ncorrelated, total = countTheNumberOfCorrelationsPerBuffer(pvals, rhovals)\n",
    "ncorrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "today = dt.datetime.now().date().strftime(\"%d/%m/%Y\")\n",
    "where = \"Biel, CH\"\n",
    "\n",
    "my_block = f\"\"\"\n",
    "\n",
    "This script updated {today} in {where}\n",
    "\n",
    "> \\u2764\\ufe0f what you do everyday\n",
    "\n",
    "_ANALYSTATHAMMERDIRT_\n",
    "\"\"\"\n",
    "\n",
    "md(my_block)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
