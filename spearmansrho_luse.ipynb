{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# sys, file and nav packages:\n",
    "import datetime as dt\n",
    "import json\n",
    "\n",
    "# math packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "# charting:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import IPython\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display\n",
    "\n",
    "start_date = '2020-03-01'\n",
    "end_date ='2021-05-31'\n",
    "\n",
    "a_qty = 20\n",
    "\n",
    "a_fail_rate = .5\n",
    "\n",
    "use_fail = False\n",
    "\n",
    "unit_label = 'p/100m'\n",
    "\n",
    "# survey data:\n",
    "dfx= pd.read_csv('resources/checked_sdata_eos_2020_21.csv')\n",
    "\n",
    "dfBeaches = pd.read_csv(\"resources/beaches_with_land_use_rates.csv\")\n",
    "dfCodes = pd.read_csv(\"resources/codes_with_group_names_2015.csv\")\n",
    "\n",
    "# set the index of the beach data to location slug\n",
    "dfBeaches.set_index('slug', inplace=True)\n",
    "\n",
    "# set the index of to codes\n",
    "dfCodes.set_index(\"code\", inplace=True)\n",
    "\n",
    "# code description map\n",
    "code_d_map = dfCodes.description\n",
    "\n",
    "# code material map\n",
    "code_m_map = dfCodes.material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes in Spearmans $\\rho$ as buffer size changes\n",
    "\n",
    "Spearmans ranked test for correlation is being used to test the association of the number of objects found on the beach with the type of land use within a defined radius of the location where the objects were found.\n",
    "\n",
    "The national survey on land use is the source for the classification of land use types. For every 100mÂ² of the national territory there is an attributed land use classification based on the analysis of aerial images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is the aggregated survey data that is being used\n",
    "fd = dfx.copy()\n",
    "fd['loc_dates'] = list(zip(fd.location, fd[\"date\"]))\n",
    "fd['date'] = pd.to_datetime(fd[\"date\"])\n",
    "\n",
    "# get rid of microplastics\n",
    "mcr = dfx[dfx.groupname == \"micro plastics (< 5mm)\"].code.unique()\n",
    "micro = [\"G112\", *mcr]\n",
    "fd = fd[~fd.code.isin(micro)].copy()\n",
    "\n",
    "# there was a data entry error\n",
    "fd.code = fd.code.replace('G207', 'G208')\n",
    "\n",
    "# the location data for the surveys\n",
    "dfb = dfBeaches.loc[fd.location.unique()].copy()\n",
    "\n",
    "# manager dict for key statisitics and\n",
    "t = {}\n",
    "\n",
    "t.update({\"nlakes\":fd[fd.w_t == 'l'].water_name_slug.nunique(),\n",
    "          \"nrivers\":fd[fd.w_t == 'r'].water_name_slug.unique(),\n",
    "         \"ncodes\":fd.code.nunique(),\n",
    "         \"quantity\":fd.quantity.sum()}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'key_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18134/1972600573.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwiw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlanduse_per_radius\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_lu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols_lu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_col_totals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_lu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0myi\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0magguse_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'key_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# methods for mapping values and aggregating data\n",
    "\n",
    "def aggregate_buffer_data(data, cols, bufferdata, label_keys, **kwargs):\n",
    "    \"\"\"Maps values of <bufferdata> to <data> using the values in data.index.\n",
    "    Each location is assigined a value from the <buffer data>. If the\n",
    "    location does not have any corresponding buffer data it is assigned 0.\n",
    "    \n",
    "    :param data: A data frame with the locations\n",
    "        of interest as the index.\n",
    "    :type data: pandas.core.frame.DataFrame\n",
    "    :param cols: A list of the new column names from\n",
    "        the buffer data\n",
    "    :type cols: list, array of column names\n",
    "    :param bufferdata: A dataframe with two columns\n",
    "        one for the landuse name and the other for the\n",
    "        cumulative sum of that feature from the buffer\n",
    "    :type bufferdata: pandas.core.frame.DataFrame\n",
    "    :param label_keys: A mapping of numerical categories to labels\n",
    "    :type label_keys: dict\n",
    "    :return: The orginal data frame with the new columns added\n",
    "    \"\"\"\n",
    "    \n",
    "    # make empty columns for the measured land use features\n",
    "    for acol in cols:\n",
    "        data[acol]= 0\n",
    "\n",
    "    # assign the land use value to each location\n",
    "    for beach in data.index:\n",
    "        # for each category of land use\n",
    "        for label in list(label_keys):\n",
    "            # assign a value\n",
    "            try:\n",
    "                new_data = bufferdata[(bufferdata.location == beach)&(bufferdata.label == label)].AS18_27.values[0]\n",
    "            except:\n",
    "                new_data = 0\n",
    "            # assign that value to the location data\n",
    "            data.loc[beach, label] = new_data\n",
    "    \n",
    "    return data\n",
    "\n",
    "# account for the area attributed to water by removing the\n",
    "# the value of water features from land use total\n",
    "def adjusted_land_use(data, col_keys):\n",
    "    \"\"\"Account for the area attributed to water by removing the\n",
    "    the value of water features from land use total.\n",
    "    \n",
    "    :param data: A data frame with the column luse_total\n",
    "    :type data: pandas.core.frame.DataFrame\n",
    "    :param col_keys: The column names of all non water land\n",
    "        use columns.\n",
    "    :type cols: list, array of column names\n",
    "    :return: The orginal data frame with the new columns added\n",
    "    \"\"\"\n",
    "    # total land use\n",
    "    data['luse_total'] = data.loc[:,list(col_keys)].sum(axis=1)\n",
    "\n",
    "    # amount attributed to water\n",
    "    data['water_value'] = data.loc[:, ['lakes','rivers']].sum(axis=1)\n",
    "\n",
    "    # the adjsuted land use\n",
    "    # remove the water value from land use stats\n",
    "    data['adjusted_land_use'] = data.luse_total - data.water_value\n",
    "    \n",
    "    return data\n",
    "\n",
    "# determine the ratio of each landuse feature to the adjusted total for each buffer\n",
    "def account_for_adj_luse(data, col_keys):\n",
    "    \"\"\"Uses the adjusted land use total to determine\n",
    "    the % total for each feature.\n",
    "    \n",
    "    :param data: A data frame with the defined land use columns\n",
    "    :type data: pandas.core.frame.DataFrame\n",
    "    :param col_keys: The column names of all non water land\n",
    "        use columns.\n",
    "    :type cols: list, array of column names\n",
    "    :return: The data frame with the part of total of the\n",
    "        adjsuted land use for each AS1827 category\n",
    "    \"\"\"\n",
    "    for label in list(col_keys.values()):\n",
    "        a_label = F\"part_{label}\"\n",
    "        data[a_label] = data[label]/data['adjusted_land_use']\n",
    "    return data\n",
    "\n",
    "# map survey results to land use stats\n",
    "def assign_luse_stat_to_survey_results(sdata, luse_data, som_cols):\n",
    "    \"\"\"Maps the land-use data for a location to all samples at that\n",
    "    location.\n",
    "    \n",
    "    :param data: A data frame with the survey data of the locations\n",
    "        of interest\n",
    "    :type data: pandas.core.frame.DataFrame\n",
    "    :param luse_data: A dataframe with the land use stats\n",
    "        with the locations of interest as index.\n",
    "    :type luse_data: pandas.core.frame.DataFrame\n",
    "    :param som_cols: The label of the land use attributes\n",
    "        that are being mapped\n",
    "    :type som_cols: list or array    \n",
    "    :return: The orginal data frame with the new columns added    \n",
    "    \"\"\"\n",
    "    for a_beach in sdata.location.unique():\n",
    "        for element in som_cols:\n",
    "            sdata.loc[sdata.location == a_beach, element] = luse_data.loc[a_beach, element]\n",
    "    return sdata\n",
    "\n",
    "# apply method and check results\n",
    "def check_hypothesis(this_data, some_codes, variables, method):\n",
    "    \"\"\"Checks the ranked correlation (or whichever method is being used)\n",
    "    of < some_codes > to < variables >.\n",
    "    \n",
    "    :param this_data: A data frame with the survey data of the locations\n",
    "        of interest\n",
    "    :type data: pandas.core.frame.DataFrame\n",
    "    :param som_codes: The label of the dependent variables being\n",
    "        tested\n",
    "    :type som_codes: list or array \n",
    "    :param variables: The label of the independent variables being\n",
    "        tested\n",
    "    :type variables: list or array \n",
    "    :param method: A scipy method that compares to arrays and returns two values.\n",
    "    :type method: scipy.stats.spearmanr or similar       \n",
    "    :return: A dictionary of values key=variable, val=correlation coeffcient or zero\n",
    "        depending on the value of p.    \n",
    "    \"\"\"\n",
    "    myresults = {}\n",
    "    for i,code in enumerate(some_codes):\n",
    "        data = this_data[this_data.code == code]\n",
    "        code_results ={code:{}}\n",
    "        for j, n in enumerate(variables):\n",
    "            corr, a_p = method(data[n], data[unit_label])\n",
    "            if a_p <= 0.05:\n",
    "                code_results[code].update({n:corr})\n",
    "            else:\n",
    "                code_results[code].update({n:\"X\"})\n",
    "        myresults.update(code_results)\n",
    "    \n",
    "    return myresults\n",
    "\n",
    "\n",
    "def make_col_totals(luse,key_labels, cols, colname='1500', idx='id'):\n",
    "    \"\"\"Convenience function to aggregate and label landuse values\n",
    "    \n",
    "    :param luse: A data frame with the survey data of the locations\n",
    "        of interest\n",
    "    :type data: pandas.core.frame.DataFrame\n",
    "    :param key_labels: The labels for the different land use categories\n",
    "    :type key_labels: list or array \n",
    "    :param  cols: The columns that need to be totaled\n",
    "    :type cols: list or array \n",
    "    :param colname: The column name for the totals.\n",
    "    :type colname: str\n",
    "    :param idx: The column for the value labels\n",
    "    :type idx: str,\n",
    "    :return: A data frame      \n",
    "    \"\"\"\n",
    "    x = luse[cols].copy()\n",
    "    \n",
    "    x.loc[colname]= x.sum(numeric_only=True, axis=0)\n",
    "    \n",
    "    y = x.loc[colname]\n",
    "\n",
    "    a_tot = pd.DataFrame(index=y.index, data=y)\n",
    "\n",
    "    a_tot[idx] = a_tot.index.map(lambda x: key_labels[x])\n",
    "    \n",
    "    return a_tot \n",
    "\n",
    "def agguse_groups(data, group_parts):\n",
    "    \"\"\"Aggregates the landuse values from the buffer output\n",
    "    \n",
    "    :param data: The buffer output from QGIS\n",
    "    :type data: pandas.core.frame.DataFrame\n",
    "    :param group_parts: A dict of the labels from the buffer data stored\n",
    "        in arrays ie.. {'buildings':[2,3,4,5,9],'ind':[1]}\n",
    "    :type group_parts: dict\n",
    "    :return: A dict with the same keys as group_parts but the\n",
    "        the values are the sum of the values in the buffer data \n",
    "        that correspond to the contents of the array.\n",
    "    \n",
    "    \"\"\"\n",
    "    wiw = {}\n",
    "    for a_group in group_parts.keys():\n",
    "        part_groups = [data.loc[x] for x in group_parts[a_group]]\n",
    "        this_g = sum(part_groups)\n",
    "        wiw.update({a_group:this_g})     \n",
    "    \n",
    "    return wiw\n",
    "def landuse_per_radius(s, key_labels=key_labels, cols_lu=cols_lu, colname=1500, idx=\"id\"):\n",
    "    b = make_col_totals(s,key_labels, cols_lu, colname=radius, idx='id').set_index(\"id\", drop=True)\n",
    "    yi= agguse_groups(b, group_parts)\n",
    "    c = pd.DataFrame.from_dict(yi, orient='index').append(b.loc[['total','water_value', 'adjusted_land_use']])\n",
    "    return c\n",
    "\n",
    "# aggregate the groups\n",
    "def aggregate_the_luse_groups(data, group_parts, as_1827_part):\n",
    "    \"\"\"Makes new columns and makes a subtotal column for the\n",
    "    newly created groups. Aggregates the functional groups defined\n",
    "    by land use.\n",
    "        \n",
    "    :param data: A data frame with the defined land use columns\n",
    "    :type data: pandas.core.frame.DataFrame\n",
    "    :param group_parts: A dictionary that maps names to a list\n",
    "        of column values.\n",
    "    :type group_parts: dict\n",
    "    :param as_1827_part: The AS1827 keys to labels dict\n",
    "    :type as_1827_part: dict\n",
    "    return: The data frame with the % of total of the\n",
    "        adjsuted land use for each functional category\n",
    "    \"\"\"\n",
    "    \n",
    "    for a_group in group_parts.keys():\n",
    "        part_groups = [as_1827_part[x] for x in group_parts[a_group]]\n",
    "        new_group = F\"% to {a_group}\"\n",
    "        data[new_group] = data.loc[:,part_groups].sum(axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def aggregate_adjust_account(data, add_these_cols, bufferdata, label_keys={}):\n",
    "    data = aggregate_buffer_data(data, add_these_cols, bufferdata, list(label_keys.values()))\n",
    "    data = adjusted_land_use(data, list(label_keys.values()))\n",
    "    data = account_for_adj_luse(data, label_keys)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def make_bufferdata(a_file_name, a_col=\"AS18_27\", label_keys={}):\n",
    "    # these are the land use results\n",
    "    d = pd.read_csv(a_file_name)\n",
    "    if \"slug\" in d.columns:\n",
    "        d.rename(columns={\"slug\":\"location\"}, inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # the buffer results from qgis\n",
    "    e = d[[a_col, \"location\"]].copy()\n",
    "\n",
    "    # make a df with location slug, landuse label and land use value:\n",
    "    for a_num in e[a_col].unique():\n",
    "        e.loc[e[a_col]==a_num, \"label\"]=label_keys[a_num]\n",
    "\n",
    "    # counting the number of points inside the buffer for each location and category\n",
    "    bufferdata = e.groupby(['location','label'], as_index=False)[a_col].count()\n",
    "    \n",
    "    return bufferdata\n",
    "\n",
    "\n",
    "def check_rho_for_this_radius(data, fd, add_these_cols, bufferdata, radius=1500, label_keys=label_keys, group_parts=group_parts,\n",
    "                              som_cols=som_cols, as_1827_part=as_1827_part, abundant_codes=[]):\n",
    "    \n",
    "    # apply the defined groups, adjust and account for\n",
    "    # the value of the water feature in the total land use\n",
    "    data = aggregate_adjust_account(data, add_these_cols, bufferdata, label_keys=label_keys)\n",
    "\n",
    "    # define the % of total land use for each group\n",
    "    s = aggregate_the_luse_groups(data, group_parts, as_1827_part)\n",
    "\n",
    "    # tag each result with the radius\n",
    "    s['dist'] = radius\n",
    "    \n",
    "    # assign the land use to the survey result\n",
    "    fd_luse = assign_luse_stat_to_survey_results(fd, s,som_cols) \n",
    "    this_data = fd_luse[[unit_label,*som_cols, 'code']]\n",
    "    \n",
    "    # check rho for each value\n",
    "    myresults = check_hypothesis(this_data, abundant_codes, som_cols, stats.spearmanr)\n",
    "    a = pd.DataFrame.from_dict(myresults, orient='index')\n",
    "    a.replace('X', 0, inplace=True)\n",
    "    a[\"dist\"] = radius\n",
    "    \n",
    "    return a, s\n",
    "\n",
    "def check_condition(x, conditions, i):\n",
    "    \n",
    "    if list(set(x)&set(conditions[i])):\n",
    "        data = conditions[i][0]        \n",
    "    elif i == 0 and not list(set(x)&set(conditions[i])):\n",
    "        data = \"Others\"    \n",
    "    else:\n",
    "        data = check_condition(x, conditions, i-1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of abundant_codes\n",
    "\n",
    "Currently the `< abundant_codes >` are defined as any object that had a value greater than `< a_qty >` at any survey. That is one possible way to identify objects that accumulate, the fail rate may be another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# decide which method to use\n",
    "agg_this = {\"quantity\":\"sum\", \"p/100m\":\"sum\", \"fail\":\"sum\"}\n",
    "c_totals = fd.groupby(\"code\", as_index=False).agg(agg_this)\n",
    "c_totals[\"fr\"] = c_totals[\"fail\"]/fd.loc_date.nunique()\n",
    "\n",
    "if use_fail:\n",
    "    abundant_codes = c_totals[c_totals.fr > a_fail_rate]\n",
    "\n",
    "else:\n",
    "    abundant_codes = fd[fd.quantity > a_qty].code.unique()\n",
    "\n",
    "# order of code index\n",
    "code_totals = fd[fd.code.isin(abundant_codes)].groupby(\"code\").quantity.sum()\n",
    "code_order = code_totals.sort_values(ascending=False).index\n",
    "\n",
    "t.update({\"qMostCommon\":fd[fd.code.isin(abundant_codes)].quantity.sum()})\n",
    "\n",
    "# either way the object description needs to be added to the survey results:\n",
    "for code in fd.code.unique():\n",
    "    fd.loc[fd.code == code, \"description\"] = code_d_map.loc[code]\n",
    "\n",
    "# the descriptions were corrected of typos\n",
    "for replaceme in to_replace:\n",
    "    fd.loc[fd.description == replaceme, \"description\"] = new_descriptions[replaceme]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1500 meters codes with an association to a landuse feature\n",
    "\n",
    "Where p <= 0.05 for Spearmans test for association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the locations that need land use data\n",
    "data = pd.DataFrame(index = fd.location.unique())\n",
    "\n",
    "# the bufferdata for this radius\n",
    "bufferdata = make_bufferdata(\"resources/buffer_output/luse_1500.csv\", a_col=\"AS18_27\", label_keys=label_keys)\n",
    "\n",
    "radius = 1500\n",
    "\n",
    "# the functional land use groups:\n",
    "these_groups = list(group_parts.keys())\n",
    "\n",
    "add_these_cols = bufferdata.label.unique()\n",
    "\n",
    "a1500, s = check_rho_for_this_radius(data, fd, add_these_cols, bufferdata, radius, label_keys=label_keys, group_parts=group_parts,\n",
    "                              som_cols=som_cols, as_1827_part=as_1827_part, abundant_codes=abundant_codes)\n",
    "\n",
    "a1500[\"quantity\"] = a1500.index.map(lambda x: code_totals.loc[x])\n",
    "a1500[\"material\"] = a1500.index.map(lambda x: code_m_map.loc[x])\n",
    "a1500.sort_values(by=\"quantity\", inplace=True)\n",
    "\n",
    "# use intersects\n",
    "water_int = fd[fd.code.isin(abundant_codes)][[\"loc_date\", \"code\", \"pcs_m\", \"quantity\", \"intersects\"]]\n",
    "for each_code in abundant_codes:\n",
    "    new_data = water_int[water_int.code == each_code][[\"intersects\", \"pcs_m\"]]\n",
    "    c, p = stats.spearmanr(new_data.pcs_m.values, new_data.intersects.values)\n",
    "    if p <= 0.05:\n",
    "        a1500.loc[each_code, \"intersects\"] = c\n",
    "    else:\n",
    "        a1500.loc[each_code, \"intersects\"] = 0\n",
    "\n",
    "totals=[]\n",
    "lnd_u = []\n",
    "totals.append(landuse_per_radius(s))\n",
    "lnd_u.append(s)\n",
    "\n",
    "a1500[\"description\"] = a1500.index.map(lambda x: code_d_map.loc[x])\n",
    "\n",
    "col_order = [a1500.columns[-1], *a1500.columns[:-1]]\n",
    "a1500 = a1500.reindex(code_order)\n",
    "a1500[col_order].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Spearmans Rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [Correlation matrix plot]\n",
    "new_column_names = {\n",
    "    \"% to buildings\":\"Buildings\",\n",
    "    \"% to ind\":\"Industries\",\n",
    "    \"% to trans\":\"Roads\",\n",
    "    \"% to recreation\":\"Recreational\",\n",
    "    \"% to agg\":\"Agriculture\",\n",
    "    \"% to woods\":\"Forests\",\n",
    "    \"% to water\":\"Rivers/canals\",\n",
    "    \"% to unproductive\":\"Unproductive\"\n",
    "}\n",
    "# a1500.set_index('description', inplace=True)\n",
    "a1500.rename(columns=new_column_names, inplace=True)\n",
    "use_these = list(new_column_names.values())\n",
    "aplot = a1500[[*use_these, \"description\"]].round(2)\n",
    "aplot.set_index(\"description\", inplace=True, drop=True)\n",
    "fig, ax= plt.subplots(figsize=(17,17))\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "kwargs = dict(annot=True, fmt=\"g\", cmap='coolwarm',\n",
    "              annot_kws={\"size\":9.5},center =0, mask=aplot==0,\n",
    "              square = True, linewidths=0.1,linecolor=\"lightgrey\",\n",
    "              cbar = False)\n",
    "\n",
    "ax = sns.heatmap(aplot, ax=ax, **kwargs)\n",
    "\n",
    "ax.set_ylabel('')\n",
    "ax.yaxis.tick_left()\n",
    "\n",
    "ax.xaxis.tick_top() \n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.set_xticklabels(use_these,rotation=90)\n",
    "       \n",
    "ax_divider = make_axes_locatable(ax)\n",
    "axins = inset_axes(ax,\n",
    "                   width=\"60%\",  # width = 5% of parent_bbox width\n",
    "                   height=\"1.5%\",  # height : 50%\n",
    "                   loc='lower center',\n",
    "                   bbox_to_anchor=(0.03, -0.03, 1, 1),\n",
    "                   bbox_transform=ax.transAxes, \n",
    "                   borderpad=0\n",
    "                   )\n",
    "\n",
    "fig.colorbar(ax.get_children()[0], cax = axins, orientation = 'horizontal', extendfrac='auto')\n",
    "# plt.savefig('output/corr_matrix_1500.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance of explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rho = aplot.corr(method='spearman')\n",
    "pval = aplot.corr(method=lambda x, y: stats.spearmanr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p = pval.applymap(lambda x: ''.join(['*' for t in [0.01,0.05,0.1] if x<=t]))\n",
    "rho.round(2).astype(str) + p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum of the total number of objects with a correlation (positive or negative) collected under the different land use categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the cumulative sum of the objects of interest under\n",
    "# the different landuse categories\n",
    "cum_sums_objs = [a1500.loc[a1500[x] != 0, \"quantity\"].sum() for x in use_these]\n",
    "a_df=pd.DataFrame(index=use_these, data=cum_sums_objs, columns=[\"total\"])\n",
    "a_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The % total of materials of the objects of interest with respect to the total number of objects collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the % total of materials of the objects of interest\n",
    "# with respect to the total amount collected\n",
    "a_total = a1500.quantity.sum()\n",
    "material_df = pd.DataFrame(a1500.groupby(\"material\").quantity.sum() / a_total).round(3)\n",
    "material_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The % total of the top 36 objects with respect to all objects collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the % total of the 36 objects included in the analysis\n",
    "# with respect to the total number of objects collected\n",
    "index = ['ratio of top 36 items over all items:','number of top 36 items:']\n",
    "data = [f\"{(round((t['qMostCommon']/t['quantity'])*100))}%\",\"{:,}\".format(round(a_total))]\n",
    "q_and_p = pd.DataFrame(data=data, index=index, columns=[\"value\"])\n",
    "q_and_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The % total of the top 20 objects with respect to all objects collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the % total of the top 20 objects included in the analysis\n",
    "# with respect to the total number of objects collected\n",
    "dT20 =a1500.iloc[:20,:]\n",
    "dT20 = dT20[['description', 'quantity']]\n",
    "\n",
    "index = ['ratio of top 20 items over all items:','number of top 20 items:']\n",
    "data = [f\"{(round((dT20.quantity.sum()/t['quantity'])*100))}%\",\"{:,}\".format(round(dT20.quantity.sum()))]\n",
    "\n",
    "q_and_p20 = pd.DataFrame(data=data, index=index, columns=[\"value\"])\n",
    "q_and_p20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cumulative totals of the top 20 objects, grouped by economic source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the broad categories:\n",
    "tobaco = [\"Tobacco\", \"Smoking related\"]\n",
    "industry = ['Industry','Construction', 'Industrial', 'Manufacturing']\n",
    "sanitary = [\"Sanitary\", \"Personal hygiene\", \"Water treatment\"]\n",
    "packaging = ['Packaging (non-food)','Packaging films nonfood or unknown', 'Paper packaging']\n",
    "food = ['Food and drinks','Foil wrappers, aluminum foil', 'Food and drinks', 'Food and drink']\n",
    "fragments = ['Plastic fragments and pieces',\n",
    "             'Plastic fragments angular <5mm',\n",
    "             'Styrofoam < 5mm', \n",
    "             'Plastic fragments rounded <5mm',\n",
    "             'Foamed  plastic <5mm',\n",
    "             'Fragmented plastics']\n",
    "\n",
    "conditions = [tobaco, industry, sanitary, packaging, food, fragments]\n",
    "\n",
    "codes = dT20.index    \n",
    "    \n",
    "for each_code in codes:\n",
    "    srcs = dfCodes.loc[each_code][[\"source\", \"source_two\", \"source_three\", \"description\"]]\n",
    "    \n",
    "    a = check_condition(srcs.values, conditions, len(conditions)-1)\n",
    "    dT20.loc[each_code, \"Type\"] = a\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "colors = {'Industry': 'firebrick', 'Tobacco': 'darkslategrey', 'Food and drinks': 'navy', 'Plastic fragments and pieces':'lightgrey',\n",
    "         'Others':'linen','Sanitary':'plum','Packaging (non-food)':'saddlebrown'}\n",
    "# N = 3\n",
    "# ind = np.arange(N)\n",
    "width = 0.6\n",
    "\n",
    "labels = list(colors.keys())\n",
    "handles = [plt.Rectangle((0,0),1,1, color=colors[label]) for label in labels]\n",
    "\n",
    "ax.barh(dT20.description, dT20.quantity, color=[colors[i] for i in dT20.Type], edgecolor='darkgrey')\n",
    "ax.invert_yaxis()  \n",
    "ax.set_ylabel('')\n",
    "ax.set_xticks([0,1000,2000,3000,4000,5000,6000,7000,8000])\n",
    "ax.set_xticklabels([0,'1,000','2,000','3,000','4,000','5,000','6,000','7,000','8,000'])\n",
    "\n",
    "ax.set_xlabel('Total item count', fontsize=16, labelpad =15)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.tick_params(labelcolor='k', labelsize=14, width=1)\n",
    "ax.yaxis.grid(color='lightgray')\n",
    "ax.xaxis.grid(color='lightgray')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "plt.legend(handles, labels, fontsize=13,facecolor='white')\n",
    "for ha in ax.legend_.legendHandles:\n",
    "    ha.set_edgecolor(\"darkgrey\")\n",
    "\n",
    "plt.grid(True)\n",
    "ax.spines['top'].set_color('0.5')\n",
    "ax.spines['right'].set_color('0.5')\n",
    "ax.spines['bottom'].set_color('0.5')\n",
    "ax.spines['left'].set_color('0.5')\n",
    "\n",
    "# plt.savefig('C:/Users/schre086/figures/land_use_ch/top_20items.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Litter items of local origin\n",
    "\n",
    "Items that have four or more positive associations with a land use category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_corr = ['Buildings', 'Industries', 'Roads', 'Recreational', 'Agriculture', 'Forests', 'Unproductive']\n",
    "\n",
    "c_count = a1500.copy()\n",
    "\n",
    "# count the total number of correlations rho < 0 or rho > 0 and p < .05\n",
    "c_count['corr_count'] = c_count[cols_corr].apply(lambda x: (x!=0).sum(), axis=1)\n",
    "\n",
    "# count the total number of positive correlations\n",
    "c_count['pos_corr_count'] = c_count[cols_corr].apply(lambda x: (x>0).sum(), axis=1)\n",
    "\n",
    "# limt only to items that have four or more correlations\n",
    "DfLocalItems = c_count[c_count.corr_count >= 4]\n",
    "\n",
    "# get the local total\n",
    "local_total = DfLocalItems.quantity.sum()\n",
    "\n",
    "# pretty print this to jupyter\n",
    "bullets = [f\"* {x}\" for x in DfLocalItems.description.unique()]\n",
    "\n",
    "b = \"\\n\".join(bullets)\n",
    "\n",
    "a_string = f\"\"\"\n",
    "* The total quantity of items that have more than four correlations, likely to be locally littered: {\"{:,}\".format(local_total)}\n",
    "* Proportion of items likely to be of local origin among top items: {int((DfLocalItems.quantity.sum()/t[\"qMostCommon\"])*100)}%\n",
    "\n",
    "There are {len(DfLocalItems.description.unique())} categories in that group:\\n\\n {b}'\n",
    "\"\"\"\n",
    "md(a_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ubiquitous items\n",
    "\n",
    "Items that have three or less positive associations with a land use category and are positively associated with river or stream intersections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DfUbiItems = c_count[(c_count.corr_count <= 3)&(c_count.intersects > 0)]\n",
    "ub_total = DfUbiItems.quantity.sum()\n",
    "\n",
    "bullets = [f\"* {x}\" for x in DfUbiItems.description.unique()]\n",
    "b = \"\\n\".join(bullets)\n",
    "\n",
    "a_string = f\"\"\"\n",
    "* The total quantity of items with less than three correlations and at least one correlation to intersects: {\"{:,}\".format(ub_total)}\n",
    "* Proportion of items likely to be locally littered among top items: {int((DfUbiItems.quantity.sum()/t[\"qMostCommon\"])*100)}%\n",
    "\n",
    "There are {len(DfUbiItems.description.unique())} categories in that group:\\n\\n {b}'\n",
    "\"\"\"\n",
    "md(a_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other items\n",
    "\n",
    "Items that have three or less positive associations with a land use category and are NOT positively associated with river or stream intersections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DfOthers = c_count[(c_count.corr_count <= 3)&(c_count.intersects <= 0)]\n",
    "other_total = DfOthers.quantity.sum()\n",
    "bullets = [f\"* {x}\" for x in DfOthers.description.unique()]\n",
    "\n",
    "b = \"\\n\".join(bullets)\n",
    "\n",
    "a_string = f\"\"\"\n",
    "* The total quantity of items with less than two positive correlations: {\"{:,}\".format(other_total)}\n",
    "* Proportion of items likely to be locally littered among top items: {int((DfOthers.quantity.sum()/t[\"qMostCommon\"])*100)}%\n",
    "\n",
    "There are {len(DfOthers.description.unique())} categories in that group:\\n\\n {b}'\n",
    "\"\"\"\n",
    "md(a_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checking if total proportion is 100%\n",
    "print('total proportion of groups:',((DfOthers.quantity.sum()/t[\"qMostCommon\"])*100) \n",
    "      + ((DfUbiItems.quantity.sum()/t[\"qMostCommon\"])*100) \n",
    "      + ((DfLocalItems.quantity.sum()/t[\"qMostCommon\"])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2000 meters codes with an association to a landuse feature\n",
    "\n",
    "Where p <= 0.05 for Spearmans test for association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the locations that need land use data\n",
    "data = pd.DataFrame(index = fd.location.unique())\n",
    "radius = 2000\n",
    "\n",
    "# the functional land use groups:\n",
    "these_groups = list(group_parts.keys())\n",
    "\n",
    "# the bufferdata for this radius\n",
    "bufferdata = make_bufferdata(\"resources/buffer_output/luse_2000.csv\", a_col=\"AS18_27\", label_keys=label_keys)\n",
    "\n",
    "add_these_cols = bufferdata.label.unique()\n",
    "\n",
    "a2000, s = check_rho_for_this_radius(data, fd, add_these_cols, bufferdata, radius, label_keys=label_keys, group_parts=group_parts,\n",
    "                              som_cols=som_cols, as_1827_part=as_1827_part, abundant_codes=abundant_codes)\n",
    "\n",
    "totals.append(landuse_per_radius(s))\n",
    "lnd_u.append(s)\n",
    "\n",
    "a2000[\"quantity\"] = a2000.index.map(lambda x: code_totals.loc[x])\n",
    "a2000[\"material\"] = a2000.index.map(lambda x: code_m_map.loc[x])\n",
    "a2000.sort_values(by=\"quantity\", inplace=True)\n",
    "\n",
    "a2000[\"description\"] = a2000.index.map(lambda x: code_d_map.loc[x])\n",
    "\n",
    "col_order = [a2000.columns[-1], *a2000.columns[:-1]]\n",
    "a2000 = a2000.reindex(code_order)\n",
    "a2000[col_order].sort_values(by=['% to buildings', '% to woods', '% to ind', '% to recreation', '% to agg'], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2500 meters codes with an association to a landuse feature\n",
    "\n",
    "Where p <= 0.05 for Spearmans test for association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the locations that need land use data\n",
    "data = pd.DataFrame(index = fd.location.unique())\n",
    "radius = 2500\n",
    "\n",
    "# the functional land use groups:\n",
    "these_groups = list(group_parts.keys())\n",
    "\n",
    "# the bufferdata for this radius\n",
    "bufferdata = make_bufferdata(\"resources/buffer_output/luse_2500.csv\", a_col=\"AS18_27\", label_keys=label_keys)\n",
    "\n",
    "add_these_cols = bufferdata.label.unique()\n",
    "\n",
    "a2500, s = check_rho_for_this_radius(data, fd, add_these_cols, bufferdata, radius, label_keys=label_keys, group_parts=group_parts,\n",
    "                              som_cols=som_cols, as_1827_part=as_1827_part, abundant_codes=abundant_codes)\n",
    "\n",
    "totals.append(landuse_per_radius(s))\n",
    "lnd_u.append(s)\n",
    "\n",
    "a2500[\"quantity\"] = a2500.index.map(lambda x: code_totals.loc[x])\n",
    "a2500[\"material\"] = a2500.index.map(lambda x: code_m_map.loc[x])\n",
    "a2500.sort_values(by=\"quantity\", inplace=True)\n",
    "\n",
    "a2500[\"description\"] = a2500.index.map(lambda x: code_d_map.loc[x])\n",
    "\n",
    "col_order = [a2500.columns[-1], *a2500.columns[:-1]]\n",
    "a2500 = a2500.reindex(code_order)\n",
    "a2500[col_order].sort_values(by=['% to buildings', '% to woods', '% to ind', '% to recreation', '% to agg'], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3000 meters codes with an association to a landuse feature\n",
    "\n",
    "Where p <= 0.05 for Spearmans test for association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the locations that need land use data\n",
    "data = pd.DataFrame(index = fd.location.unique())\n",
    "radius = 3000\n",
    "\n",
    "# the functional land use groups:\n",
    "these_groups = list(group_parts.keys())\n",
    "\n",
    "# the bufferdata for this radius\n",
    "bufferdata = make_bufferdata(\"resources/buffer_output/luse_3000.csv\", a_col=\"AS18_27\", label_keys=label_keys)\n",
    "\n",
    "add_these_cols = bufferdata.label.unique()\n",
    "\n",
    "a3000, s = check_rho_for_this_radius(data, fd, add_these_cols, bufferdata, radius, label_keys=label_keys, group_parts=group_parts,\n",
    "                              som_cols=som_cols, as_1827_part=as_1827_part, abundant_codes=abundant_codes)\n",
    "totals.append(landuse_per_radius(s))\n",
    "lnd_u.append(s)\n",
    "\n",
    "a3000[\"quantity\"] = a3000.index.map(lambda x: code_totals.loc[x])\n",
    "a3000[\"material\"] = a3000.index.map(lambda x: code_m_map.loc[x])\n",
    "a3000.sort_values(by=\"quantity\", inplace=True)\n",
    "\n",
    "a3000[\"description\"] = a3000.index.map(lambda x: code_d_map.loc[x])\n",
    "\n",
    "col_order = [a3000.columns[-1], *a3000.columns[:-1]]\n",
    "a3000 = a3000.reindex(code_order)\n",
    "a3000[col_order].sort_values(by=['% to buildings', '% to woods', '% to ind', '% to recreation', '% to agg'], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3500 meters codes with an association to a landuse feature\n",
    "\n",
    "Where p <= 0.05 for Spearmans test for association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the locations that need land use data\n",
    "data = pd.DataFrame(index = fd.location.unique())\n",
    "radius = 3500\n",
    "\n",
    "# the functional land use groups:\n",
    "these_groups = list(group_parts.keys())\n",
    "\n",
    "# the bufferdata for this radius\n",
    "bufferdata = make_bufferdata(\"resources/buffer_output/luse_3500.csv\", a_col=\"AS18_27\", label_keys=label_keys)\n",
    "\n",
    "add_these_cols = bufferdata.label.unique()\n",
    "\n",
    "a3500, s = check_rho_for_this_radius(data, fd, add_these_cols, bufferdata, radius, label_keys=label_keys, group_parts=group_parts,\n",
    "                              som_cols=som_cols, as_1827_part=as_1827_part, abundant_codes=abundant_codes)\n",
    "\n",
    "totals.append(landuse_per_radius(s))\n",
    "lnd_u.append(s)\n",
    "\n",
    "a3500[\"quantity\"] = a3500.index.map(lambda x: code_totals.loc[x])\n",
    "a3500[\"material\"] = a3500.index.map(lambda x: code_m_map.loc[x])\n",
    "a3500.sort_values(by=\"quantity\", inplace=True)\n",
    "\n",
    "# use intersects\n",
    "water_int = fd[fd.code.isin(abundant_codes)][[\"loc_date\", \"code\", \"pcs_m\", \"quantity\", \"intersects\"]]\n",
    "for each_code in abundant_codes:\n",
    "    new_data = water_int[water_int.code == each_code][[\"intersects\", \"pcs_m\"]]\n",
    "    c, p = stats.spearmanr(new_data.pcs_m.values, new_data.intersects.values)\n",
    "    if p <= 0.05:\n",
    "        a3500.loc[each_code, \"intersects\"] = c\n",
    "    else:\n",
    "        a3500.loc[each_code, \"intersects\"] = 0\n",
    "\n",
    "a3500[\"description\"] = a3500.index.map(lambda x: code_d_map.loc[x])\n",
    "\n",
    "col_order = [a3500.columns[-1], *a3500.columns[:-1]]\n",
    "a3500 = a3500.reindex(code_order)\n",
    "a3500[col_order].sort_values(by=['% to buildings', '% to woods', '% to ind', '% to recreation', '% to agg'], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Spearmans Rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [Correlation matrix plot]\n",
    "new_column_names = {\n",
    "    \"% to buildings\":\"Buildings\",\n",
    "    \"% to ind\":\"Industries\",\n",
    "    \"% to trans\":\"Roads\",\n",
    "    \"% to recreation\":\"Recreational\",\n",
    "    \"% to agg\":\"Agriculture\",\n",
    "    \"% to woods\":\"Forests\",\n",
    "    \"% to water\":\"Rivers/canals\",\n",
    "    \"% to unproductive\":\"Unproductive\"\n",
    "}\n",
    "# a1500.set_index('description', inplace=True)\n",
    "a3500.rename(columns=new_column_names, inplace=True)\n",
    "use_these = list(new_column_names.values())\n",
    "aplot = a3500[[*use_these, \"description\"]].round(2)\n",
    "aplot.set_index(\"description\", inplace=True, drop=True)\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(17,17))\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "kwargs = dict(annot=True, fmt=\"g\", cmap='coolwarm',\n",
    "              annot_kws={\"size\":9.5},center =0, mask=aplot==0,\n",
    "              square = True, linewidths=0.1,linecolor=\"lightgrey\",\n",
    "              cbar = False)\n",
    "\n",
    "ax = sns.heatmap(aplot, ax = ax, **kwargs)\n",
    "\n",
    "ax.set_ylabel('')\n",
    "ax.yaxis.tick_left()\n",
    "\n",
    "ax.xaxis.tick_top() \n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.set_xticklabels(use_these,rotation=90)\n",
    "       \n",
    "ax_divider = make_axes_locatable(ax)\n",
    "axins = inset_axes(ax,\n",
    "                   width=\"60%\",  # width = 5% of parent_bbox width\n",
    "                   height=\"1.5%\",  # height : 50%\n",
    "                   loc='lower center',\n",
    "                   bbox_to_anchor=(0.03, -0.03, 1, 1),\n",
    "                   bbox_transform=ax.transAxes, \n",
    "                   borderpad=0\n",
    "                   )\n",
    "\n",
    "fig.colorbar(ax.get_children()[0], cax = axins, orientation = 'horizontal', extendfrac='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Litter items of local origin\n",
    "\n",
    "Items that have four or more positive associations with a land use category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cols_corr = ['Buildings', 'Industries', 'Roads', 'Recreational', 'Agriculture', 'Forests', 'Unproductive']\n",
    "\n",
    "c_count = a3500.copy()\n",
    "\n",
    "# count the total number of correlations rho < 0 or rho > 0 and p < .05\n",
    "c_count['corr_count'] = c_count[cols_corr].apply(lambda x: (x!=0).sum(), axis=1)\n",
    "\n",
    "# count the total number of positive correlations\n",
    "c_count['pos_corr_count'] = c_count[cols_corr].apply(lambda x: (x>0).sum(), axis=1)\n",
    "\n",
    "# limt only to items that have four or more correlations\n",
    "DfLocalItems = c_count[c_count.corr_count >= 4]\n",
    "\n",
    "# get the local total\n",
    "local_total = DfLocalItems.quantity.sum()\n",
    "\n",
    "# pretty print this to jupyter\n",
    "bullets = [f\"* {x}\" for x in DfLocalItems.description.unique()]\n",
    "\n",
    "b = \"\\n\".join(bullets)\n",
    "\n",
    "a_string = f\"\"\"\n",
    "* The total quantity of items that have more than four correlations, likely to be locally littered: {\"{:,}\".format(local_total)}\n",
    "* Proportion of items likely to be of local origin among top items: {int((DfLocalItems.quantity.sum()/t[\"qMostCommon\"])*100)}%\n",
    "\n",
    "There are {len(DfLocalItems.description.unique())} categories in that group:\\n\\n {b}'\n",
    "\"\"\"\n",
    "md(a_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ubiquitous items\n",
    "\n",
    "Items that have three or less positive associations with a land use category and are positively associated with river or stream intersections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DfUbiItems = c_count[(c_count.corr_count <= 3)&(c_count.intersects > 0)]\n",
    "ub_total = DfUbiItems.quantity.sum()\n",
    "\n",
    "bullets = [f\"* {x}\" for x in DfUbiItems.description.unique()]\n",
    "b = \"\\n\".join(bullets)\n",
    "\n",
    "a_string = f\"\"\"\n",
    "* The total quantity of items with less than three correlations and at least one correlation to intersects: {\"{:,}\".format(ub_total)}\n",
    "* Proportion of items likely to be locally littered among top items: {int((DfUbiItems.quantity.sum()/t[\"qMostCommon\"])*100)}%\n",
    "\n",
    "There are {len(DfUbiItems.description.unique())} categories in that group:\\n\\n {b}'\n",
    "\"\"\"\n",
    "md(a_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other items\n",
    "\n",
    "Items that have three or less positive associations with a land use category and are NOT positively associated with river or stream intersections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DfOthers = c_count[(c_count.corr_count <= 2)&(c_count.intersects <= 0)]\n",
    "other_total = DfOthers.quantity.sum()\n",
    "bullets = [f\"* {x}\" for x in DfOthers.description.unique()]\n",
    "\n",
    "b = \"\\n\".join(bullets)\n",
    "\n",
    "a_string = f\"\"\"\n",
    "* The total quantity of items with less than two positive correlations: {\"{:,}\".format(other_total)}\n",
    "* Proportion of items likely to be locally littered among top items: {int((DfOthers.quantity.sum()/t[\"qMostCommon\"])*100)}%\n",
    "\n",
    "There are {len(DfOthers.description.unique())} categories in that group:\\n\\n {b}'\n",
    "\"\"\"\n",
    "md(a_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checking if total proportion is 100%\n",
    "print('total proportion of groups:',((DfOthers.quantity.sum()/t[\"qMostCommon\"])*100) \n",
    "      + ((DfUbiItems.quantity.sum()/t[\"qMostCommon\"])*100) \n",
    "      + ((DfLocalItems.quantity.sum()/t[\"qMostCommon\"])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4000 meters codes with an association to a landuse feature\n",
    "\n",
    "Where p <= 0.05 for Spearmans test for association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the locations that need land use data\n",
    "data = pd.DataFrame(index = fd.location.unique())\n",
    "radius = 4000\n",
    "\n",
    "# the functional land use groups:\n",
    "these_groups = list(group_parts.keys())\n",
    "\n",
    "# the bufferdata for this radius\n",
    "bufferdata = make_bufferdata(\"resources/buffer_output/luse_4000.csv\", a_col=\"AS18_27\", label_keys=label_keys)\n",
    "\n",
    "add_these_cols = bufferdata.label.unique()\n",
    "\n",
    "a4000, s = check_rho_for_this_radius(data, fd, add_these_cols, bufferdata, radius, label_keys=label_keys, group_parts=group_parts,\n",
    "                              som_cols=som_cols, as_1827_part=as_1827_part, abundant_codes=abundant_codes)\n",
    "\n",
    "totals.append(landuse_per_radius(s))\n",
    "lnd_u.append(s)\n",
    "\n",
    "a4000[\"quantity\"] = a4000.index.map(lambda x: code_totals.loc[x])\n",
    "a4000[\"material\"] = a4000.index.map(lambda x: code_m_map.loc[x])\n",
    "a4000.sort_values(by=\"quantity\", inplace=True)\n",
    "\n",
    "a4000[\"description\"] = a4000.index.map(lambda x: code_d_map.loc[x])\n",
    "\n",
    "col_order = [a4000.columns[-1], *a4000.columns[:-1]]\n",
    "a4000 = a4000.reindex(code_order)\n",
    "a4000[col_order].sort_values(by=['% to buildings', '% to woods', '% to ind', '% to recreation', '% to agg'], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4500 meters codes with an association to a landuse feature\n",
    "\n",
    "Where p <= 0.05 for Spearmans test for association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the locations that need land use data\n",
    "data = pd.DataFrame(index = fd.location.unique())\n",
    "radius = 4500\n",
    "\n",
    "# the functional land use groups:\n",
    "these_groups = list(group_parts.keys())\n",
    "\n",
    "# the bufferdata for this radius\n",
    "bufferdata = make_bufferdata(\"resources/buffer_output/luse_4500.csv\", a_col=\"AS18_27\", label_keys=label_keys)\n",
    "\n",
    "add_these_cols = bufferdata.label.unique()\n",
    "\n",
    "a4500, s = check_rho_for_this_radius(data, fd, add_these_cols, bufferdata, radius, label_keys=label_keys, group_parts=group_parts,\n",
    "                              som_cols=som_cols, as_1827_part=as_1827_part, abundant_codes=abundant_codes)\n",
    "\n",
    "totals.append(landuse_per_radius(s))\n",
    "lnd_u.append(s)\n",
    "\n",
    "a4500[\"quantity\"] = a4500.index.map(lambda x: code_totals.loc[x])\n",
    "a4500[\"material\"] = a4500.index.map(lambda x: code_m_map.loc[x])\n",
    "a4500.sort_values(by=\"quantity\", inplace=True)\n",
    "\n",
    "a4500[\"description\"] = a4500.index.map(lambda x: code_d_map.loc[x])\n",
    "\n",
    "col_order = [a4500.columns[-1], *a4500.columns[:-1]]\n",
    "a4500 = a4500.reindex(code_order)\n",
    "a4500[col_order].sort_values(by=['% to buildings', '% to woods', '% to ind', '% to recreation', '% to agg'], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5000 meters codes with an association to a landuse feature\n",
    "\n",
    "Where p <= 0.05 for Spearmans test for association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the locations that need land use data\n",
    "data = pd.DataFrame(index = fd.location.unique())\n",
    "radius = 5000\n",
    "\n",
    "# the functional land use groups:\n",
    "these_groups = list(group_parts.keys())\n",
    "\n",
    "# the bufferdata for this radius\n",
    "bufferdata = make_bufferdata(\"resources/buffer_output/luse_5k.csv\", a_col=\"AS18_27\", label_keys=label_keys)\n",
    "\n",
    "add_these_cols = bufferdata.label.unique()\n",
    "\n",
    "a5000, s = check_rho_for_this_radius(data, fd, add_these_cols, bufferdata, radius, label_keys=label_keys, group_parts=group_parts,\n",
    "                              som_cols=som_cols, as_1827_part=as_1827_part, abundant_codes=abundant_codes)\n",
    "\n",
    "totals.append(landuse_per_radius(s))\n",
    "lnd_u.append(s)\n",
    "\n",
    "a5000[\"quantity\"] = a5000.index.map(lambda x: code_totals.loc[x])\n",
    "a5000[\"material\"] = a5000.index.map(lambda x: code_m_map.loc[x])\n",
    "a5000.sort_values(by=\"quantity\", inplace=True)\n",
    "\n",
    "a5000[\"description\"] = a5000.index.map(lambda x: code_d_map.loc[x])\n",
    "\n",
    "col_order = [a5000.columns[-1], *a5000.columns[:-1]]\n",
    "a5000 = a5000.reindex(code_order)\n",
    "a5000[col_order].sort_values(by=['% to buildings', '% to woods', '% to ind', '% to recreation', '% to agg'], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10000 meters codes with an association to a landuse feature\n",
    "\n",
    "Where p <= 0.05 for Spearmans test for association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the locations that need land use data\n",
    "data = pd.DataFrame(index = fd.location.unique())\n",
    "radius = 10000\n",
    "\n",
    "# the functional land use groups:\n",
    "these_groups = list(group_parts.keys())\n",
    "\n",
    "# the bufferdata for this radius\n",
    "bufferdata = make_bufferdata(\"resources/buffer_output/luse_10k.csv\", a_col=\"AS18_27\", label_keys=label_keys)\n",
    "\n",
    "add_these_cols = bufferdata.label.unique()\n",
    "\n",
    "a10k, s = check_rho_for_this_radius(data, fd, add_these_cols, bufferdata, radius, label_keys=label_keys, group_parts=group_parts,\n",
    "                              som_cols=som_cols, as_1827_part=as_1827_part, abundant_codes=abundant_codes)\n",
    "\n",
    "totals.append(landuse_per_radius(s))\n",
    "lnd_u.append(s)\n",
    "\n",
    "a10k[\"quantity\"] = a10k.index.map(lambda x: code_totals.loc[x])\n",
    "a10k[\"material\"] = a10k.index.map(lambda x: code_m_map.loc[x])\n",
    "a10k.sort_values(by=\"quantity\", inplace=True)\n",
    "\n",
    "a10k[\"description\"] = a10k.index.map(lambda x: code_d_map.loc[x])\n",
    "\n",
    "col_order = [a10k.columns[-1], *a10k.columns[:-1]]\n",
    "a10k = a10k.reindex(code_order)\n",
    "a10k[col_order].sort_values(by=['% to buildings', '% to woods', '% to ind', '% to recreation', '% to agg'], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total correlations, total positive correlations and weight for each buffer radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the total land use for each buffer zone\n",
    "t_lu_by_r = pd.concat(totals, axis=1)\n",
    "\n",
    "# the column names to aggregate\n",
    "cols = list(new_column_names.values())\n",
    "\n",
    "# these buffer values need the columns renamed\n",
    "dfs_oldnames = [a2000, a2500, a3000, a4000, a4500, a5000, a10k]\n",
    "dfs_newnames = [data.rename(columns=new_column_names) for data in dfs_oldnames]\n",
    "\n",
    "# combined all the buffer values\n",
    "dfs = [a1500,dfs_newnames[0], dfs_newnames[1], dfs_newnames[2], a3500, dfs_newnames[3], dfs_newnames[4], dfs_newnames[5], dfs_newnames[6]]\n",
    "\n",
    "# count the total correlations and positive correlations\n",
    "for data in dfs:\n",
    "    data[\"count\"] = data[cols].apply(lambda x: (x!=0).sum(), axis=1)\n",
    "    data['positive'] = data[cols].apply(lambda x: (x>0).sum(), axis=1)\n",
    "\n",
    "# convert meters to kilometers for index and printing\n",
    "con_to_km = [x/1000 for x in t_lu_by_r.columns]\n",
    "\n",
    "# for each radius get the total and positive count\n",
    "total_correlation_count = {}\n",
    "pos_correlations = {}\n",
    "for i,a_radius in enumerate(con_to_km):\n",
    "    \n",
    "    data = dfs[i]\n",
    "    \n",
    "    total_count = data[\"count\"].sum()\n",
    "    pos_count = data[\"positive\"].sum()\n",
    "    label = a_radius\n",
    "    total_correlation_count.update({label:total_count})\n",
    "    pos_correlations.update({label:pos_count})\n",
    "    \n",
    "    \n",
    "# combine the correlation totals per radius in to one df\n",
    "t_corrs = pd.DataFrame.from_dict(total_correlation_count, orient=\"index\", columns=[\"# of correlations\"])\n",
    "\n",
    "# add positive correlations\n",
    "for k,v in pos_correlations.items():\n",
    "    t_corrs.loc[k, \"positive correlations\"] = v\n",
    "\n",
    "# add the weight factor\n",
    "for i,a_radius in enumerate(con_to_km):\n",
    "    data=dfs[i]    \n",
    "    data['weight'] = (data['positive'] * data['quantity'])  \n",
    "    t_corrs.loc[a_radius, \"weight\"] = data[\"weight\"].sum()\n",
    "\n",
    "t_corrs[\"positive correlations\"] = t_corrs[\"positive correlations\"].astype(\"int\")\n",
    "t_corrs[\"weight\"] = t_corrs[\"weight\"].astype(\"int\")\n",
    "t_corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Changes in Spearmans $\\rho$ at different buffer sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Spearmans $\\rho$ evaluated for expanded foams, fragmented plastics, snack wrappers, production pelltets and cigarettes at different buffer zone radii for % attributed to buildings*\n",
    "\n",
    "*Table of results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comps = pd.concat(dfs)\n",
    "comps.reset_index(inplace=True)\n",
    "comps.rename(columns={'index':'code'}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "data = comps[comps.code.isin(['G27', 'Gfrags', 'G30', 'Gfoam', 'G112'])].copy()\n",
    "aval = \"Buildings\"\n",
    "variables=[aval]\n",
    "data[variables] = data[variables].astype('float').round(2)\n",
    "data.sort_values(by=aval, inplace=True)\n",
    "\n",
    "sns.lineplot(data=data, x='dist', y=aval, hue='code')\n",
    "ax.set_ylabel('Rho', fontsize=14)\n",
    "ax.set_xlabel('buffer radius meters', fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1,1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes of land use profile for different buffer zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the radius of the buffer zone changes the land use mix changes. Defining the radius of the buffer zone is determined by the scale at which the reporting is being done. For the report to Switzerland the target administrative level was the municipality. Therefore a radius of 1500m was appropriate, given the geographic size of a municipality in Switzerland.\n",
    "\n",
    "*__Below:__ The percent total of land attributed to each category at each buffer radius* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the row label for the total combined land use\n",
    "total ='adjusted_land_use'\n",
    "totaldf = t_lu_by_r.loc[total]\n",
    "\n",
    "# divide the individual land use categories by the total land-use\n",
    "# for each radius\n",
    "landuse = ['agg', 'buildings', 'ind', 'recreation', 'trans', 'unproductive', 'woods']\n",
    "adf = t_lu_by_r.loc[landuse].copy()\n",
    "for element in totaldf.index:\n",
    "    adf[element] =  ((adf[element]/totaldf.loc[element])*100).astype(\"int\")\n",
    "\n",
    "# pretty print\n",
    "pprint =adf.applymap(lambda x:f\"{x}%\")\n",
    "pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data =adf.values\n",
    "labels = adf.index\n",
    "colors = adf.index\n",
    "xlabels = [str(x) for x in adf.columns]\n",
    "\n",
    "colors = ['bisque','lightcoral','k','orchid','lightgrey','saddlebrown', 'forestgreen']\n",
    "\n",
    "bottom = [0]*(len(adf.columns))\n",
    "\n",
    "width = 0.8      # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "for i,group in enumerate(data):\n",
    "    ax.bar(xlabels, group, width, bottom=bottom, label=labels[i], color = colors[i])\n",
    "    bottom += group\n",
    "\n",
    "\n",
    "ax.set_ylabel('Land-use profile [%]', fontsize=16)\n",
    "\n",
    "ax.set_xlabel(\"Buffer zone radius [m]\", labelpad =15, fontsize=16)\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "ax.spines['top'].set_color('0.5')\n",
    "ax.spines['right'].set_color('0.5')\n",
    "ax.spines['bottom'].set_color('0.5')\n",
    "ax.spines['left'].set_color('0.5')\n",
    "ax.set_ylim(0,100)\n",
    "\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.tick_params(labelcolor='k', labelsize=14, width=1)\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1,1), facecolor = 'white', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Above:__ The percent total of land use at the different buffer radius. As the radius increases the % total attributed to forest and agriculture gets larger* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "survey_data = dfx.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "survey_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# explanatory variables that are being considered\n",
    "#luse_exp = ['% to buildings', '% to recreation', '% to agg', '% to woods', 'streets km', 'intersects']\n",
    "luse_exp = ['Buildings [%]','Industrial [%]', 'Recreational [%]', 'Agricultural [%]', 'Forests [%]', 'Unproductive [%]', 'Road network \\nlength [km]', 'Rivers/canals [#]']\n",
    "# columns needed\n",
    "use_these_cols = ['loc_date' ,\n",
    "                  'date',\n",
    "                  '% to buildings',\n",
    "                  '% to trans',\n",
    "                  '% to recreation',\n",
    "                  '% to agg',\n",
    "                  '% to woods',\n",
    "                  '% to ind', \n",
    "                  '% to unproductive',\n",
    "                  'population',\n",
    "                  'water_name_slug',\n",
    "                  'streets km',\n",
    "                  'intersects',\n",
    "                  'groupname',\n",
    "                  'code'\n",
    "                 ]\n",
    "\n",
    "# the land use data was unvailable for these municipalities\n",
    "no_land_use = ['Walenstadt', 'Weesen', 'Glarus Nord', 'Quarten']\n",
    "\n",
    "# slice the data by start and end date, remove the locations with no land use data\n",
    "use_these_args = ((survey_data.date >= start_date)&(survey_data.date <= end_date)&(~survey_data.city.isin(no_land_use)))\n",
    "survey_data = survey_data[use_these_args].copy()\n",
    "\n",
    "# format the data and column names\n",
    "survey_data['date'] = pd.to_datetime(survey_data.date)\n",
    "\n",
    "# work off a copy\n",
    "new_som_data = survey_data.copy()\n",
    "\n",
    "# adjust the fail rate for this aggregation of data\n",
    "new_som_data['fail'] = True\n",
    "new_som_data.loc[new_som_data.quantity == 0, 'fail'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the survey total for each survey indifferent of object\n",
    "dfdt = new_som_data.groupby(use_these_cols[:-2], as_index=False).agg({unit_label:'sum', 'quantity':'sum'})\n",
    "\n",
    "\n",
    "dfdt = new_som_data.groupby(use_these_cols[:-2], as_index=False).agg({unit_label:'sum', 'quantity':'sum'})\n",
    "dfdt.columns = ['loc_date','date','Built-up environment [%]', '% to tran', 'Recreational [%]', 'Agriculture [%]', \n",
    "                'Forests [%]', 'Industries [%]', 'Unproductive land [%]', 'Population', 'water_name_slug', 'Road network \\nlength [km]', 'Rivers/canals [#]', 'p/100 m','quantity']\n",
    "\n",
    "# method to get the ranked correlation of pcs_m to each explanatory variable\n",
    "def make_plot_with_spearmans(data, ax, n):\n",
    "    sns.scatterplot(data=data, x=n, y=unit_label, ax=ax, color='black', s=30, edgecolor='white', alpha=0.6)\n",
    "    corr, a_p = stats.spearmanr(data[n], data[unit_label])\n",
    "    return ax, corr, a_p\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axs = plt.subplots(1,4, figsize=(9,3), sharey=True)\n",
    "\n",
    "data = dfdt.copy()\n",
    "\n",
    "perc_cols = ['Built-up environment [%]','Industries [%]', 'Recreational [%]', 'Agriculture [%]', 'Forests [%]', 'Unproductive land [%]']\n",
    "\n",
    "data[perc_cols] = data[perc_cols].apply(lambda x:x*100)\n",
    "\n",
    "cols1 = ['Built-up environment [%]','Industries [%]', 'Recreational [%]', 'Agriculture [%]']\n",
    "#cols2 = ['Forests [%]', 'Unproductive [%]', 'Road network \\nlength [km]', 'Rivers/canals [#]']\n",
    "for i, n in enumerate(cols1):\n",
    "    ax=axs[i]\n",
    "    \n",
    "    # the ECDF of the land use variable\n",
    "    the_data = ECDF(data[n].values)\n",
    "    sns.lineplot(x=the_data.x, y= (the_data.y)*100, ax=ax, color='dodgerblue', label=\"% of surface area\" )\n",
    "    \n",
    "    # get the median % of land use for each variable under consideration from the data\n",
    "    the_median = data[n].median()\n",
    "    \n",
    "    # plot the median and drop horzontal and vertical lines\n",
    "    ax.scatter([the_median], 50, color='red',s=50, linewidth=2, zorder=100, label=\"the median\")\n",
    "    ax.vlines(x=the_median, ymin=0, ymax=50, color='red', linewidth=2)\n",
    "    ax.hlines(xmax=the_median, xmin=0, y=50, color='red', linewidth=2)\n",
    "    \n",
    "    #remove the legend from ax   \n",
    "    ax.get_legend().remove()\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Share of \\nsurveys [%]\", labelpad = 15)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # add the median value from all locations to the ax title\n",
    "    ax.set_title(F\"median: {(round(the_median, 2))}\",fontsize=12, loc='left')\n",
    "    ax.set_xlabel(n, fontsize=14, labelpad=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('C:/Users/schre086/figures/land_use_ch/land_use_1500_A.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "fig, axs = plt.subplots(1,4, figsize=(9,3), sharey=True)\n",
    "\n",
    "#cols1 = ['Buildings [%]','Industrial [%]', 'Recreational [%]', 'Agricultural [%]']\n",
    "cols2 = ['Forests [%]', 'Unproductive land [%]', 'Road network \\nlength [km]', 'Rivers/canals [#]']\n",
    "for i, n in enumerate(cols2):\n",
    "    ax=axs[i]\n",
    "    \n",
    "    # the ECDF of the land use variable\n",
    "    the_data = ECDF(data[n].values)\n",
    "    sns.lineplot(x=the_data.x, y= (the_data.y)*100, ax=ax, color='dodgerblue', label=\"% of surface area\" )\n",
    "    \n",
    "    # get the median % of land use for each variable under consideration from the data\n",
    "    the_median = data[n].median()\n",
    "    \n",
    "    # plot the median and drop horzontal and vertical lines\n",
    "    ax.scatter([the_median], 50, color='red',s=50, linewidth=2, zorder=100, label=\"the median\")\n",
    "    ax.vlines(x=the_median, ymin=0, ymax=50, color='red', linewidth=2)\n",
    "    ax.hlines(xmax=the_median, xmin=0, y=50, color='red', linewidth=2)\n",
    "    \n",
    "    #remove the legend from ax   \n",
    "    ax.get_legend().remove()\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Share of \\nsurveys [%]\", labelpad = 15)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # add the median value from all locations to the ax title\n",
    "    ax.set_title(F\"median: {(round(the_median, 2))}\",fontsize=12, loc='left')\n",
    "    ax.set_xlabel(n, fontsize=14, labelpad=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('C:/Users/schre086/figures/land_use_ch/land_use_1500_B.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
